{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"MAZE_DATA = [\"\"\"\n    -10;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -10;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-10;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-1;\n    -1;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-1;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -1;-10;-1;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -1;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -10;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-1;\n    -10;-10;-1;-10;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-1;\n    -10;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-1;-1;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-10;\n    -1;-1;-10;-10;\n    -1;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -10;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-10;\n    -10;-1;-1;-1;\n    -10;-1;-1;-1;\n    -10;-10;-1;-1;\n    -10;-10;-10;-1;\n        \"\"\"]","metadata":{"execution":{"iopub.status.busy":"2024-08-07T02:31:57.942722Z","iopub.execute_input":"2024-08-07T02:31:57.943328Z","iopub.status.idle":"2024-08-07T02:31:57.949843Z","shell.execute_reply.started":"2024-08-07T02:31:57.943301Z","shell.execute_reply":"2024-08-07T02:31:57.948776Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"maze_data_list = [\n    \"\"\"\n    -10;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -10;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-10;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-1;\n    -1;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-1;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -1;-10;-1;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -1;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -10;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-1;\n    -10;-10;-1;-10;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-1;\n    -10;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-1;-1;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-10;\n    -1;-1;-10;-10;\n    -1;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -10;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-10;\n    -10;-1;-1;-1;\n    -10;-1;-1;-1;\n    -10;-10;-1;-1;\n    -10;-10;-10;-1;\n    \"\"\",\n    \"\"\"\n    -1;-10;-10;-10;\n    -1;-1;-10;-10;\n    -1;-1;-1;-10;\n    -10;-10;-1;-10;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -10;-1;-10;-10;\n    -1;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-10;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-1;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-1;\n    -1;-10;-1;-10;\n    -10;-1;-10;-10;\n    -1;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-10;\n    -10;-1;-10;-1;\n    -1;-10;-1;-1;\n    -10;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -10;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-10;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-1;\n    -10;-1;-1;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-10;\n    \"\"\",\n    \"\"\"\n    -1;-1;-10;-10;\n    -10;-10;-1;-10;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-1;\n    -10;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-10;\n    -10;-1;-10;-1;\n    -1;-10;-1;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-1;\n    -10;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-1;\n    -1;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -10;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-1;\n    -1;-10;-1;-10;\n    -10;-1;-10;-10;\n    -1;-1;-1;-10;\n    -10;-10;-1;-10;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-10;\n    \"\"\",\n    \"\"\"\n    -1;-1;-10;-10;\n    -10;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-10;\n    -1;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -1;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-10;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -1;-10;-1;-1;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-1;\n    -10;-1;-1;-1;\n    -10;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-10;\n    \"\"\",\n    \"\"\"\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-1;\n    -1;-10;-1;-10;\n    -10;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-1;\n    -10;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-10;-10;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-1;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-1;\n    -10;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-10;-10;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-1;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -10;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-1;\n    -10;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-10;-10;-1;\n    \"\"\"\n]","metadata":{"execution":{"iopub.status.busy":"2024-08-07T02:31:57.955406Z","iopub.execute_input":"2024-08-07T02:31:57.955683Z","iopub.status.idle":"2024-08-07T02:31:57.971518Z","shell.execute_reply.started":"2024-08-07T02:31:57.955661Z","shell.execute_reply":"2024-08-07T02:31:57.970686Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"maze_data_list_alot = [\n    \"\"\"\n    -10;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -10;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-10;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-1;\n    -1;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-1;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -1;-10;-1;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -1;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -10;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-1;\n    -10;-10;-1;-10;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-1;\n    -10;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-1;-1;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-10;\n    -1;-1;-10;-10;\n    -1;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -10;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-10;\n    -10;-1;-1;-1;\n    -10;-1;-1;-1;\n    -10;-10;-1;-1;\n    -10;-10;-10;-1;\n    \"\"\",\n    \"\"\"\n    -1;-10;-10;-10;\n    -1;-1;-10;-10;\n    -1;-1;-1;-10;\n    -10;-10;-1;-10;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -10;-1;-10;-10;\n    -1;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-10;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-1;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-1;\n    -1;-10;-1;-10;\n    -10;-1;-10;-10;\n    -1;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-10;\n    -10;-1;-10;-1;\n    -1;-10;-1;-1;\n    -10;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -10;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-10;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-1;\n    -10;-1;-1;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-10;\n    \"\"\",\n    \"\"\"\n    -1;-1;-10;-10;\n    -10;-10;-1;-10;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-1;\n    -10;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-10;\n    -10;-1;-10;-1;\n    -1;-10;-1;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-1;\n    -10;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-1;\n    -1;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -10;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-1;\n    -1;-10;-1;-10;\n    -10;-1;-10;-10;\n    -1;-1;-1;-10;\n    -10;-10;-1;-10;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-10;\n    \"\"\",\n    \"\"\"\n    -1;-1;-10;-10;\n    -10;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-10;\n    -1;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-1;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -1;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-10;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -1;-10;-1;-1;\n    -1;-10;-10;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-10;-10;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-1;\n    -10;-1;-1;-1;\n    -10;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-10;\n    \"\"\",\n    \"\"\"\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-1;\n    -1;-10;-1;-10;\n    -10;-1;-10;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-1;\n    -10;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-10;-10;-1;\n    -1;-10;-10;-1;\n    -10;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-10;-10;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-1;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -1;-10;-1;-1;\n    -10;-1;-10;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-10;-10;-10;\n    -1;-1;-10;-10;\n    -10;-1;-1;-1;\n    -1;-10;-1;-10;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-10;-10;-1;\n    -1;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-1;\n    -10;-1;-1;-10;\n    -1;-10;-1;-10;\n    -1;-1;-10;-1;\n    -1;-10;-1;-10;\n    -1;-10;-10;-1;\n    -10;-1;-10;-10;\n    -10;-10;-1;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-10;\n    -10;-10;-10;-1;\n    -1;-1;-10;-10;\n    -1;-10;-1;-1;\n    -10;-10;-10;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-1;\n    -10;-1;-1;-10;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-1;-10;-1;\n    -10;-1;-1;-10;\n    -10;-10;-1;-1;\n    -10;-10;-10;-1;\n    \"\"\",\n#     \"\"\"\n#     -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-10;\n# -1;-1;-10;-10;\n# -1;-10;-1;-10;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-10;\n# -10;-1;-10;-1;\n# -10;-10;-1;-1;\n# -10;-1;-10;-1;\n# -10;-10;-1;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-10;\n# -10;-1;-10;-1;\n# -10;-10;-1;-10;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -10;-10;-10;-1;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -10;-10;-1;-1;\n# -1;-10;-10;-10;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -1;-10;-1;-10;\n# -1;-10;-10;-10;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -1;-10;-10;-10;\n# -1;-1;-10;-10;\n# -10;-1;-1;-1;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -10;-10;-1;-1;\n# -1;-1;-10;-10;\n# -10;-1;-1;-1;\n# -10;-10;-1;-1;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-1;\n# -10;-10;-10;-1;\n# -1;-1;-10;-1;\n# -10;-1;-1;-10;\n# -10;-10;-1;-10;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-1;-10;-10;\n# -10;-1;-1;-1;\n# -10;-10;-1;-10;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-1;-10;-1;\n# -10;-1;-1;-10;\n# -1;-10;-1;-10;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -10;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -10;-1;-10;-10;\n# -1;-1;-1;-10;\n# -10;-10;-1;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -10;-10;-10;-1;\n# -10;-1;-10;-1;\n# -10;-1;-1;-10;\n# -10;-1;-1;-1;\n# -10;-1;-1;-10;\n# -10;-10;-1;-1;\n# -10;-1;-10;-10;\n# -10;-1;-1;-1;\n# -10;-1;-1;-10;\n# -10;-10;-1;-1;\n#     \"\"\",\n# \"\"\"\n# -1;-1;-10;-10;\n# -1;-10;-1;-10;\n# -1;-10;-10;-10;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -1;-1;-1;-10;\n# -10;-10;-1;-10;\n# -1;-1;-10;-10;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-10;-10;-10;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -1;-1;-10;-1;\n# -1;-10;-1;-10;\n# -10;-1;-10;-1;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -10;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-1;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -1;-10;-1;-10;\n# -10;-10;-10;-1;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -10;-1;-10;-10;\n# -1;-10;-1;-1;\n# -1;-1;-10;-1;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-10;\n# -1;-10;-10;-1;\n# -1;-1;-10;-1;\n# -10;-10;-1;-10;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -1;-1;-1;-10;\n# -10;-10;-1;-1;\n# -1;-1;-10;-10;\n# -1;-10;-1;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -10;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -1;-10;-10;-10;\n# -10;-1;-10;-1;\n# -10;-1;-1;-10;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -10;-10;-1;-10;\n# -10;-1;-10;-1;\n# -10;-1;-1;-1;\n# -10;-1;-1;-1;\n# -10;-1;-1;-10;\n# -10;-10;-1;-10;\n# -10;-1;-10;-1;\n# -10;-10;-1;-1;\n# -10;-10;-10;-1;\n# \"\"\",\n# \"\"\"\n# -1;-1;-10;-10;\n# -1;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-10;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-10;\n# -1;-10;-10;-10;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-1;-10;-10;\n# -10;-10;-1;-10;\n# -10;-1;-10;-1;\n# -10;-10;-1;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -10;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-10;\n# -10;-1;-10;-1;\n# -10;-1;-1;-10;\n# -1;-10;-1;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -10;-1;-10;-10;\n# -1;-1;-1;-1;\n# -10;-10;-1;-1;\n# -1;-10;-10;-10;\n# -1;-1;-10;-1;\n# -1;-1;-1;-10;\n# -10;-10;-1;-10;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -10;-1;-1;-10;\n# -1;-10;-1;-10;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-10;\n# -1;-10;-10;-1;\n# -10;-1;-10;-10;\n# -10;-1;-1;-1;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-10;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-1;\n# -10;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-10;\n# -10;-1;-10;-1;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -10;-1;-10;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -1;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-1;-10;-10;\n# -1;-10;-1;-1;\n# -1;-1;-10;-10;\n# -1;-10;-1;-10;\n# -10;-10;-10;-1;\n# -10;-1;-10;-1;\n# -10;-1;-1;-10;\n# -1;-10;-1;-1;\n# -10;-10;-10;-1;\n# -10;-1;-10;-1;\n# -10;-10;-1;-1;\n# -10;-1;-10;-1;\n# -10;-10;-1;-1;\n# -10;-1;-10;-1;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-10;-1;-1;\n# \"\"\",\n# \"\"\"\n# -10;-1;-10;-10;\n# -1;-1;-1;-10;\n# -1;-10;-1;-10;\n# -1;-1;-10;-10;\n# -1;-10;-1;-10;\n# -1;-1;-10;-10;\n# -1;-1;-1;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-10;\n# -1;-10;-10;-10;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -10;-1;-10;-1;\n# -10;-10;-1;-1;\n# -10;-10;-10;-1;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -10;-1;-10;-1;\n# -1;-10;-1;-1;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-1;\n# -10;-10;-1;-10;\n# -1;-10;-10;-1;\n# -1;-10;-10;-10;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-10;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-1;-10;-1;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -10;-10;-1;-10;\n# -1;-1;-10;-1;\n# -10;-10;-1;-1;\n# -10;-1;-10;-1;\n# -10;-1;-1;-10;\n# -1;-10;-1;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -10;-1;-10;-10;\n# -10;-1;-1;-1;\n# -1;-10;-1;-10;\n# -10;-1;-10;-10;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -1;-1;-1;-10;\n# -10;-10;-1;-10;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -10;-1;-10;-10;\n# -1;-10;-1;-1;\n# -1;-1;-10;-10;\n# -1;-10;-1;-1;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -10;-1;-10;-1;\n# -1;-1;-1;-10;\n# -1;-10;-1;-10;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -10;-10;-10;-1;\n# -1;-10;-10;-1;\n# -10;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -1;-10;-10;-10;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -10;-10;-1;-10;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -10;-1;-10;-1;\n# -10;-1;-1;-10;\n# -10;-1;-1;-1;\n# -10;-1;-1;-10;\n# -10;-10;-1;-1;\n# -10;-1;-10;-1;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-10;-1;-1;\n# \"\"\",\n# \"\"\"\n# -1;-10;-10;-10;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -1;-1;-1;-10;\n# -1;-10;-1;-10;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-10;\n# -10;-1;-10;-10;\n# -1;-10;-1;-10;\n# -1;-1;-10;-1;\n# -10;-1;-1;-1;\n# -10;-10;-1;-10;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -10;-10;-1;-1;\n# -1;-10;-10;-10;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -10;-10;-10;-1;\n# -1;-1;-10;-10;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -10;-1;-10;-10;\n# -1;-1;-1;-10;\n# -1;-10;-1;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -10;-10;-1;-1;\n# -10;-1;-10;-10;\n# -1;-10;-1;-1;\n# -10;-1;-10;-1;\n# -10;-10;-1;-10;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-10;-1;-1;\n# -10;-1;-10;-1;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-1;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -10;-10;-1;-1;\n# -10;-1;-10;-1;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -1;-1;-1;-10;\n# -1;-10;-1;-10;\n# -10;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -1;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -10;-10;-1;-10;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -1;-10;-1;-10;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -10;-10;-1;-10;\n# -1;-10;-10;-1;\n# -10;-1;-10;-1;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-10;-1;-1;\n# -1;-10;-10;-1;\n# -10;-10;-10;-1;\n# -1;-10;-10;-1;\n# -1;-1;-10;-10;\n# -10;-1;-1;-10;\n# -1;-10;-1;-1;\n# -10;-1;-10;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-10;\n# -10;-1;-1;-1;\n# -10;-1;-1;-10;\n# -10;-1;-1;-1;\n# -10;-10;-1;-1;\n# -10;-1;-10;-10;\n# -10;-10;-1;-1;\n# \"\"\"\n]","metadata":{"execution":{"iopub.status.busy":"2024-08-07T02:31:58.072260Z","iopub.execute_input":"2024-08-07T02:31:58.072512Z","iopub.status.idle":"2024-08-07T02:31:58.095033Z","shell.execute_reply.started":"2024-08-07T02:31:58.072485Z","shell.execute_reply":"2024-08-07T02:31:58.094018Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import gymnasium as gym\nfrom gymnasium import spaces\nimport numpy as np\nfrom PIL import Image, ImageDraw\n\nclass CustomMazeEnvCNNIMGML(gym.Env):\n    def __init__(self, max_steps_per_episode=100, maze_data_list=None, maze_size=10, random_start=False):\n        super(CustomMazeEnvCNNIMGML, self).__init__()\n        \n        self.maze_size = maze_size\n        self.max_steps_per_episode = max_steps_per_episode\n        self.action_space = spaces.Discrete(4)  # [0: up, 1: right, 2: down, 3: left]\n        \n        # Define image size for DQN\n        self.image_size = 84\n        self.observation_space = spaces.Box(low=0, high=255, shape=(self.image_size, self.image_size, 3), dtype=np.uint8)\n\n        self.mazes = []\n        self.current_maze_index = 0\n        self.random_start = random_start\n        self.episode = 0\n        \n        self.reward = 0\n        self.done = False\n        self.is_success = False\n        \n        self.state = None\n        self.start = None\n        self.goal = (self.maze_size - 1, self.maze_size - 1)\n\n        self.visit_counts = np.zeros((self.maze_size, self.maze_size), dtype=np.int32)\n        self.current_step = 0\n\n        for maze_data in maze_data_list:\n            self.mazes.append(self.initialize_maze(maze_data))\n        \n        self.maze = self.mazes[self.current_maze_index]\n        \n        \n    def initialize_maze(self, input_string):\n        maze_size = self.maze_size\n        rows = input_string.strip().split('\\n')\n        top_wall = np.zeros((maze_size, maze_size), dtype=np.uint8)\n        right_wall = np.zeros((maze_size, maze_size), dtype=np.uint8)\n        bottom_wall = np.zeros((maze_size, maze_size), dtype=np.uint8)\n        left_wall = np.zeros((maze_size, maze_size), dtype=np.uint8)\n\n        parsed_data = []\n        for row in rows:\n            parsed_data.append([int(x) for x in row.split(';') if x != ''])\n\n        for i in range(maze_size):\n            for j in range(maze_size):\n                state_index = i * maze_size + j\n                actions = parsed_data[state_index]\n                bottom_wall[i, j] = 1 if actions[0] == -10 else 0\n                right_wall[i, j] = 1 if actions[1] == -10 else 0\n                left_wall[i, j] = 1 if actions[2] == -10 else 0\n                top_wall[i, j] = 1 if actions[3] == -10 else 0\n\n        return np.stack([top_wall, right_wall, bottom_wall, left_wall], axis=0)\n        \n    def _get_obs(self):\n        return self._render_maze()\n\n    def reset(self, seed=42, options=None):\n        new_seed = seed + self.episode\n        super().reset(seed=new_seed)\n        self.episode += 1\n\n        if not self.random_start:\n            self.start = (0, 0)\n        else:\n            self.start = (self.np_random.integers(0, self.maze_size), self.np_random.integers(0, self.maze_size))\n        \n        self.current_step = 0\n        self.state = self.start\n        self.visit_counts[self.state] += 1\n        \n        # Change to the next maze\n        self.current_maze_index = (self.current_maze_index + 1) % len(self.mazes)\n        self.maze = self.mazes[self.current_maze_index]\n        return self._get_obs(), {}\n\n    def step(self, action):\n        self.current_step += 1\n        x, y = self.state\n        new_x, new_y = x, y\n\n        # Define possible moves\n        if action == 0:  # up\n            new_x = max(0, x - 1)\n        elif action == 1:  # right\n            new_y = min(self.maze_size - 1, y + 1)\n        elif action == 2:  # down\n            new_x = min(self.maze_size - 1, x + 1)\n        elif action == 3:  # left\n            new_y = max(0, y - 1)\n\n        # Check for walls or boundaries\n        wall_hit = False\n        if action == 0 and (x == 0 or self.maze[0, x, y] == 1):  # Top wall or top edge\n            wall_hit = True\n        elif action == 1 and (y == self.maze_size - 1 or self.maze[1, x, y] == 1):  # Right wall or right edge\n            wall_hit = True\n        elif action == 2 and (x == self.maze_size - 1 or self.maze[2, x, y] == 1):  # Bottom wall or bottom edge\n            wall_hit = True\n        elif action == 3 and (y == 0 or self.maze[3, x, y] == 1):  # Left wall or left edge\n            wall_hit = True\n        \n        \n        # Determine reward and update state\n        if wall_hit:\n            self.reward = -10\n        else:\n            self.state = (new_x, new_y)\n            if self.state == self.goal:\n                self.reward = 10\n            else:\n                self.reward = -1  # Default step cost\n        \n        self.visit_counts[self.state] += 1\n\n        # Check if goal is reached or max steps are reached\n        self.done = False\n        self.is_success = False\n        if self.state == self.goal:\n            self.done = True\n            self.is_success = True\n        elif self.current_step >= self.max_steps_per_episode:\n            self.done = True\n            self.is_success = False\n        \n        return self._get_obs(), self.reward, self.done, False, {\"is_success\": self.is_success}\n\n    \n    def _render_maze(self):\n        img = Image.new('RGB', (self.image_size, self.image_size), color=(255, 255, 255))\n        draw = ImageDraw.Draw(img)\n\n        cell_size = min(self.image_size // self.maze_size, self.image_size // self.maze_size)\n        maze_pixel_size = cell_size * self.maze_size\n        offset_x = (self.image_size - maze_pixel_size) // 2\n        offset_y = (self.image_size - maze_pixel_size) // 2\n\n        # Draw the maze walls\n        for i in range(self.maze_size):\n            for j in range(self.maze_size):\n                x, y = offset_x + j * cell_size, offset_y + i * cell_size\n                walls = [(0, [(x, y), (x + cell_size, y)]),             # Top\n                        (1, [(x + cell_size, y), (x + cell_size, y + cell_size)]),  # Right\n                        (2, [(x, y + cell_size), (x + cell_size, y + cell_size)]),  # Bottom\n                        (3, [(x, y), (x, y + cell_size)])]            # Left\n                for idx, line in walls:\n                    if self.maze[idx, i, j]:\n                        draw.line(line, fill=(0, 0, 0), width=1)\n\n        # Function to draw centered cells\n        def draw_centered_cell(x, y, color, size_factor=0.6):\n            size = int(cell_size * size_factor)\n            center_x = x + cell_size // 2\n            center_y = y + cell_size // 2\n            top_left_x = center_x - size // 2\n            top_left_y = center_y - size // 2\n            draw.rectangle([top_left_x, top_left_y, \n                            top_left_x + size, top_left_y + size], \n                        fill=color)\n\n        # Draw start (green), goal (red), and agent (blue)\n        start_x, start_y = offset_x + self.start[1] * cell_size, offset_y + self.start[0] * cell_size\n        goal_x, goal_y = offset_x + self.goal[1] * cell_size, offset_y + self.goal[0] * cell_size\n        agent_x, agent_y = offset_x + self.state[1] * cell_size, offset_y + self.state[0] * cell_size\n\n        draw_centered_cell(start_x, start_y, (0, 255, 0))  # Green start\n        draw_centered_cell(goal_x, goal_y, (255, 0, 0))    # Red goal\n        \n        # Draw agent as a centered circle\n        agent_size = int(cell_size * 0.4)\n        center_x = agent_x + cell_size // 2\n        center_y = agent_y + cell_size // 2\n        top_left_x = center_x - agent_size // 2\n        top_left_y = center_y - agent_size // 2\n        draw.ellipse([top_left_x, top_left_y, \n                    top_left_x + agent_size, top_left_y + agent_size], \n                    fill=(0, 0, 255))  # Blue agent\n\n        return np.array(img)\n\n    def render(self, mode='human'):\n        img = self._render_maze()\n        if mode == 'human':\n            Image.fromarray(img).show()\n        elif mode == 'rgb_array':\n            return img","metadata":{"execution":{"iopub.status.busy":"2024-08-07T02:31:58.096897Z","iopub.execute_input":"2024-08-07T02:31:58.097385Z","iopub.status.idle":"2024-08-07T02:31:58.590595Z","shell.execute_reply.started":"2024-08-07T02:31:58.097354Z","shell.execute_reply":"2024-08-07T02:31:58.589613Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import gymnasium as gym\nfrom gymnasium import spaces\nimport numpy as np\n\nclass CustomMazeEnvMlpImprovedML(gym.Env):\n    def __init__(self, max_steps_per_episode=100, maze_data_list=None, maze_size=10, random_start=False):\n        super(CustomMazeEnvMlpImprovedML, self).__init__()\n        \n        \n        # Define the size of the maze\n        self.maze_size = maze_size\n        self.max_steps_per_episode = max_steps_per_episode\n        \n        # Define action and observation space\n        self.action_space = spaces.Discrete(4)  # [0: up, 1: right, 2: down, 3: left]\n        self.observation_space = spaces.Box(low=0, high=127, shape=(self.maze_size * self.maze_size,), dtype=np.uint8)\n\n        self.mazes = []\n        self.current_maze_index = 0\n        self.random_start = random_start\n        self.episode = 0\n        \n        self.reward = 0\n        self.done = False\n        self.is_success = False\n\n        # Initial state\n        self.state = None\n        self.start = None\n        self.goal = (self.maze_size - 1, self.maze_size - 1)\n\n        # Initialize visit counts\n        self.visit_counts = np.zeros((self.maze_size, self.maze_size), dtype=np.int32)\n        self.current_step = 0\n        \n        for maze_data in maze_data_list:\n            self.mazes.append(self.initialize_maze(maze_data))\n        \n        self.maze = self.mazes[self.current_maze_index]\n        \n\n    def initialize_maze(self, input_string):\n        rows = input_string.strip().split('\\n')\n        maze = np.zeros(self.maze_size * self.maze_size, dtype=np.uint8)\n\n        parsed_data = []\n        for row in rows:\n            parsed_data.append([int(x) for x in row.split(';') if x != ''])\n\n        for i in range(self.maze_size):\n            for j in range(self.maze_size):\n                state_index = i * self.maze_size + j\n                actions = parsed_data[state_index]\n                \n                state = 0\n                state |= (1 if actions[3] == -10 else 0)  # Top wall\n                state |= (1 if actions[1] == -10 else 0) << 1  # Right wall\n                state |= (1 if actions[0] == -10 else 0) << 2  # Bottom wall\n                state |= (1 if actions[2] == -10 else 0) << 3  # Left wall\n                state |= (1 if (i, j) == self.start else 0) << 4  # Start position\n                state |= (1 if (i, j) == self.goal else 0) << 5  # Goal position\n                \n                maze[state_index] = state\n\n        return maze\n\n    def _get_obs(self):\n        obs = self.maze.copy()\n        x, y = self.state\n        obs[x * self.maze_size + y] |= 1 << 6  # Set the agent bit\n        return obs\n\n    def reset(self, seed=42, options=None):\n        new_seed = seed + self.episode\n        super().reset(seed=new_seed)\n        self.episode += 1\n\n        if not self.random_start:\n            self.start = (0, 0)\n        else:\n            self.start = (self.np_random.integers(0, self.maze_size), self.np_random.integers(0, self.maze_size))\n        \n        self.current_step = 0\n        self.state = self.start\n        self.visit_counts[self.state] += 1\n        \n        self.current_maze_index = (self.current_maze_index + 1) % len(self.mazes)\n        self.maze = self.mazes[self.current_maze_index]\n        return self._get_obs(), {}\n\n    def step(self, action):\n        self.current_step += 1\n        x, y = self.state\n        new_x, new_y = x, y\n\n        # Define possible moves\n        if action == 0:  # up\n            new_x = max(0, x - 1)\n        elif action == 1:  # right\n            new_y = min(self.maze_size - 1, y + 1)\n        elif action == 2:  # down\n            new_x = min(self.maze_size - 1, x + 1)\n        elif action == 3:  # left\n            new_y = max(0, y - 1)\n\n        state_index = x * self.maze_size + y\n\n        # Check for walls\n        wall_hit = False\n        if action == 0 and (x == 0 or self.maze[state_index] & 1):  # Top wall\n            wall_hit = True\n        elif action == 1 and (y == self.maze_size - 1 or self.maze[state_index] & (1 << 1)):  # Right wall\n            wall_hit = True\n        elif action == 2 and (x == self.maze_size - 1 or self.maze[state_index] & (1 << 2)):  # Bottom wall\n            wall_hit = True\n        elif action == 3 and (y == 0 or self.maze[state_index] & (1 << 3)):  # Left wall\n            wall_hit = True\n        \n        # Determine reward and update state\n        if wall_hit:\n            self.reward = -10\n        else:\n            self.state = (new_x, new_y)\n            if self.state == self.goal:\n                self.reward = 10\n            else:\n                self.reward = -1  # Default step cost\n        \n        self.visit_counts[self.state] += 1\n\n        # Check if goal is reached or max steps are reached\n        self.done = False\n        self.is_success = False\n        truncated = False\n        if self.state == self.goal:\n            self.done = True\n            self.is_success = True\n        elif self.current_step >= self.max_steps_per_episode:\n            self.done = True\n            self.is_success = False\n            truncated = True\n        \n        return self._get_obs(), self.reward, self.done, truncated, {\"is_success\": self.is_success}\n    \n    def render(self, mode='human'):\n        maze_render = np.full((self.maze_size * 2 + 1, self.maze_size * 2 + 1), ' ', dtype=str)\n        \n        # Draw walls\n        for i in range(self.maze_size):\n            for j in range(self.maze_size):\n                cell_y, cell_x = i * 2 + 1, j * 2 + 1\n                state_index = i * self.maze_size + j\n                state = self.maze[state_index]\n                \n                if state & 1:  # Top wall\n                    maze_render[cell_y - 1, cell_x] = '─'\n                if state & (1 << 1):  # Right wall\n                    maze_render[cell_y, cell_x + 1] = '│'\n                if state & (1 << 2):  # Bottom wall\n                    maze_render[cell_y + 1, cell_x] = '─'\n                if state & (1 << 3):  # Left wall\n                    maze_render[cell_y, cell_x - 1] = '│'\n\n        # Mark start, goal, and current position\n        start_y, start_x = 1, 1\n        goal_y, goal_x = self.maze_size * 2 - 1, self.maze_size * 2 - 1\n        agent_y, agent_x = self.state[0] * 2 + 1, self.state[1] * 2 + 1\n\n        maze_render[start_y, start_x] = 'S'\n        maze_render[goal_y, goal_x] = 'G'\n        maze_render[agent_y, agent_x] = 'A'\n\n        # Print the maze\n        for row in maze_render:\n            print(''.join(row))\n        print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T02:31:58.592631Z","iopub.execute_input":"2024-08-07T02:31:58.593002Z","iopub.status.idle":"2024-08-07T02:31:58.629354Z","shell.execute_reply.started":"2024-08-07T02:31:58.592968Z","shell.execute_reply":"2024-08-07T02:31:58.627615Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import gymnasium as gym\nfrom gymnasium import spaces\nimport numpy as np\n\nclass CustomMazeEnvCnnML(gym.Env):\n    def __init__(self, max_steps_per_episode=100, maze_data_list=None, maze_size=10, random_start=False):\n        super(CustomMazeEnvCnnML, self).__init__()\n        \n        # Define the size of the maze\n        self.maze_size = maze_size\n        self.max_steps_per_episode = max_steps_per_episode\n            \n        # Define action and observation space\n        self.action_space = spaces.Discrete(4)  # [0: up, 1: right, 2: down, 3: left]\n        self.observation_space = spaces.Box(low=0, high=127, shape=(1, self.maze_size, self.maze_size), dtype=np.uint8)\n\n        self.mazes = []\n        self.current_maze_index = 0\n        self.random_start = random_start\n        self.episode = 0\n        \n        self.reward = 0\n        self.done = False\n        self.is_success = False\n\n        # Initial state\n        self.state = None\n        self.start = None\n        self.goal = (self.maze_size - 1, self.maze_size - 1)\n        \n        self.visit_counts = np.zeros((self.maze_size, self.maze_size), dtype=np.int32)\n        self.current_step = 0\n\n        for maze_data in maze_data_list:\n            self.mazes.append(self.initialize_maze(maze_data))\n        \n        self.maze = self.mazes[self.current_maze_index]\n        \n    def initialize_maze(self, input_string):\n        maze_size = self.maze_size\n        rows = input_string.strip().split('\\n')\n\n        maze = np.zeros((maze_size, maze_size), dtype=np.uint8)\n\n        parsed_data = []\n        for row in rows:\n            parsed_data.append([int(x) for x in row.split(';') if x != ''])\n\n        for i in range(maze_size):\n            for j in range(maze_size):\n                state_index = i * maze_size + j\n                actions = parsed_data[state_index]\n                \n                state = 0\n                state |= (1 if actions[3] == -10 else 0)  # Top wall\n                state |= (1 if actions[1] == -10 else 0) << 1  # Right wall\n                state |= (1 if actions[0] == -10 else 0) << 2  # Bottom wall\n                state |= (1 if actions[2] == -10 else 0) << 3  # Left wall\n                state |= (1 if (i, j) == self.start else 0) << 4  # Start position\n                state |= (1 if (i, j) == self.goal else 0) << 5  # Goal position\n                \n                maze[i, j] = state\n        \n        return maze\n        \n    def _get_obs(self):\n        obs = self.maze.copy()\n        agent_x, agent_y = self.state\n        obs[agent_x, agent_y] |= 1 << 6  # Set the agent bit\n        return obs\n\n    def reset(self, seed=42, options=None):\n        new_seed = seed + self.episode\n        super().reset(seed=new_seed)\n        self.episode += 1\n\n        if not self.random_start:\n            self.start = (0, 0)\n        else:\n            self.start = (self.np_random.integers(0, self.maze_size), self.np_random.integers(0, self.maze_size))\n        \n        self.current_step = 0\n        self.state = self.start\n        self.visit_counts[self.state] += 1\n        \n        self.current_maze_index = (self.current_maze_index + 1) % len(self.mazes)\n        self.maze = self.mazes[self.current_maze_index]\n        return self._get_obs(), {}\n\n    def step(self, action):\n        self.current_step += 1\n        x, y = self.state\n        new_x, new_y = x, y\n\n        # Define possible moves\n        if action == 0:  # up\n            new_x = max(0, x - 1)\n        elif action == 1:  # right\n            new_y = min(self.maze_size - 1, y + 1)\n        elif action == 2:  # down\n            new_x = min(self.maze_size - 1, x + 1)\n        elif action == 3:  # left\n            new_y = max(0, y - 1)\n\n        # Check for walls or boundaries\n        wall_hit = False\n        if action == 0 and (x == 0 or self.maze[x, y] & 1):  # Top wall or top edge\n            wall_hit = True\n        elif action == 1 and (y == self.maze_size - 1 or self.maze[x, y] & (1 << 1)):  # Right wall or right edge\n            wall_hit = True\n        elif action == 2 and (x == self.maze_size - 1 or self.maze[x, y] & (1 << 2)):  # Bottom wall or bottom edge\n            wall_hit = True\n        elif action == 3 and (y == 0 or self.maze[x, y] & (1 << 3)):  # Left wall or left edge\n            wall_hit = True\n        \n        # Determine reward and update state\n        if wall_hit:\n            self.reward = -10\n        else:\n            self.state = (new_x, new_y)\n            if self.state == self.goal:\n                self.reward = 10\n            else:\n                self.reward = -1  # Default step cost\n        \n        self.visit_counts[self.state] += 1\n\n        # Check if goal is reached or max steps are reached\n        self.done = False\n        self.is_success = False\n        if self.state == self.goal:\n            self.done = True\n            self.is_success = True\n        elif self.current_step >= self.max_steps_per_episode:\n            self.done = True\n            self.is_success = False\n        \n        return self._get_obs(), self.reward, self.done, False, {\"is_success\": self.is_success}\n\n    \n    def _state_to_binary(self, state):\n        return f\"{state:07b}\"\n\n    def render_binary(self):\n        for i in range(self.maze_size):\n            for j in range(self.maze_size):\n                state = self.maze[i, j]\n                if self.state == (i, j):\n                    state |= 1 << 6  # Set agent bit if it's the current position\n                binary = self._state_to_binary(state)\n                print(f\"{binary} \", end=\"\")\n            print()  # New line after each row\n        print()  # Empty line at the end\n\n    def render(self, mode='human'):\n        maze_render = np.full((self.maze_size * 2 + 1, self.maze_size * 2 + 1), ' ', dtype=str)\n        \n        # Draw walls\n        for i in range(self.maze_size):\n            for j in range(self.maze_size):\n                cell_y, cell_x = i * 2 + 1, j * 2 + 1\n                cell_state = self.maze[i, j]\n                if cell_state & 1:  # Top wall\n                    maze_render[cell_y - 1, cell_x] = '─'\n                if cell_state & (1 << 1):  # Right wall\n                    maze_render[cell_y, cell_x + 1] = '│'\n                if cell_state & (1 << 2):  # Bottom wall\n                    maze_render[cell_y + 1, cell_x] = '─'\n                if cell_state & (1 << 3):  # Left wall\n                    maze_render[cell_y, cell_x - 1] = '│'\n\n        # Mark start, goal, and current position\n        start_y, start_x = 1, 1\n        goal_y, goal_x = self.maze_size * 2 - 1, self.maze_size * 2 - 1\n        agent_y, agent_x = self.state[0] * 2 + 1, self.state[1] * 2 + 1\n\n        maze_render[start_y, start_x] = 'S'\n        maze_render[goal_y, goal_x] = 'G'\n        maze_render[agent_y, agent_x] = 'A'\n\n        # Print the maze\n        for row in maze_render:\n            print(''.join(row))\n        print(\"\\n\")\n\n        # Print binary representation\n        print(\"Binary representation of the maze state:\")\n        self.render_binary()","metadata":{"execution":{"iopub.status.busy":"2024-08-07T02:31:58.631079Z","iopub.execute_input":"2024-08-07T02:31:58.631511Z","iopub.status.idle":"2024-08-07T02:31:58.761231Z","shell.execute_reply.started":"2024-08-07T02:31:58.631476Z","shell.execute_reply":"2024-08-07T02:31:58.760088Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import gymnasium as gym\nfrom gymnasium import spaces\nimport numpy as np\n\nclass CustomMazeEnvMlpML(gym.Env):\n    def __init__(self, max_steps_per_episode=100, maze_data_list=None, maze_size=10, random_start=False):\n        super(CustomMazeEnvMlpML, self).__init__()\n        \n        \n        # Define the size of the maze\n        self.maze_size = maze_size\n        self.max_steps_per_episode = max_steps_per_episode\n        \n        # Define action and observation space\n        self.action_space = spaces.Discrete(4)  # [0: up, 1: right, 2: down, 3: left]\n        self.observation_space = spaces.Box(low=0, high=1, shape=(self.maze_size * self.maze_size,), dtype=np.uint8)\n\n        self.mazes = []\n        self.current_maze_index = 0\n        self.random_start = random_start\n        self.episode = 0\n        \n        self.reward = 0\n        self.done = False\n        self.is_success = False\n\n        # Initial state\n        self.state = None\n        self.start = None\n        self.goal = (self.maze_size - 1, self.maze_size - 1)\n\n        # Initialize visit counts\n        self.visit_counts = np.zeros((self.maze_size, self.maze_size), dtype=np.int32)\n        self.current_step = 0\n\n        for maze_data in maze_data_list:\n            self.mazes.append(self.initialize_maze(maze_data))\n        \n        self.maze = self.mazes[self.current_maze_index]\n        \n\n    def initialize_maze(self, input_string):\n        maze_size = self.maze_size\n        rows = input_string.strip().split('\\n')\n\n        top_wall = np.zeros((maze_size, maze_size), dtype=np.uint8)\n        right_wall = np.zeros((maze_size, maze_size), dtype=np.uint8)\n        bottom_wall = np.zeros((maze_size, maze_size), dtype=np.uint8)\n        left_wall = np.zeros((maze_size, maze_size), dtype=np.uint8)\n\n        parsed_data = []\n        for row in rows:\n            parsed_data.append([int(x) for x in row.split(';') if x != ''])\n\n\n        for i in range(maze_size):\n            for j in range(maze_size):\n                state_index = i * maze_size + j\n                actions = parsed_data[state_index]\n                bottom_wall[i, j] = 1 if actions[0] == -10 else 0\n                right_wall[i, j] = 1 if actions[1] == -10 else 0\n                left_wall[i, j] = 1 if actions[2] == -10 else 0\n                top_wall[i, j] = 1 if actions[3] == -10 else 0\n\n        return np.stack([top_wall, right_wall, bottom_wall, left_wall], axis=0)\n\n    def _get_obs(self):\n        obs = np.zeros(self.maze_size * self.maze_size, dtype=np.uint8)\n        obs[self.state[0] * self.maze_size + self.state[1]] = 1  # Agent position\n        return obs\n\n    def reset(self, seed=42, options=None):\n        # Reset the state of the environment to an initial state\n        new_seed = seed + self.episode\n        super().reset(seed=new_seed)\n        self.episode += 1\n\n        if not self.random_start:\n            self.start = (0, 0)\n        else:\n            self.start = (self.np_random.integers(0, self.maze_size), self.np_random.integers(0, self.maze_size))\n        \n        self.current_step = 0\n        self.state = self.start\n        self.visit_counts[self.state] += 1\n\n        self.current_maze_index = (self.current_maze_index + 1) % len(self.mazes)\n        self.maze = self.mazes[self.current_maze_index]\n        return self._get_obs(), {}\n\n    def step(self, action):\n        self.current_step += 1\n        \n        x, y = self.state\n        new_x, new_y = x, y\n\n        # Define possible moves\n        if action == 0:  # up\n            new_x = max(0, x - 1)\n        elif action == 1:  # right\n            new_y = min(self.maze_size - 1, y + 1)\n        elif action == 2:  # down\n            new_x = min(self.maze_size - 1, x + 1)\n        elif action == 3:  # left\n            new_y = max(0, y - 1)\n\n        # Check for walls or boundaries\n        wall_hit = False\n        if action == 0 and (x == 0 or self.maze[0, x, y] == 1):  # Top wall or top edge\n            wall_hit = True\n        elif action == 1 and (y == self.maze_size - 1 or self.maze[1, x, y] == 1):  # Right wall or right edge\n            wall_hit = True\n        elif action == 2 and (x == self.maze_size - 1 or self.maze[2, x, y] == 1):  # Bottom wall or bottom edge\n            wall_hit = True\n        elif action == 3 and (y == 0 or self.maze[3, x, y] == 1):  # Left wall or left edge\n            wall_hit = True\n        \n        # Determine reward and update state\n        if wall_hit:\n            self.reward = -10\n        else:\n            self.state = (new_x, new_y)\n            if self.state == self.goal:\n                self.reward = 10\n            else:\n                self.reward = -1  # Default step cost\n        \n        self.visit_counts[self.state] += 1\n\n        # Check if goal is reached or max steps are reached\n        self.done = False\n        self.is_success = False\n        if self.state == self.goal:\n            self.done = True\n            self.is_success = True\n        elif self.current_step >= self.max_steps_per_episode:\n            self.done = True\n            self.is_success = False\n        \n        return self._get_obs(), self.reward, self.done, False, {\"is_success\": self.is_success}\n    \n    def render(self, mode='human'):\n        maze_render = np.full((self.maze_size * 2 + 1, self.maze_size * 2 + 1), ' ', dtype=str)\n        \n        # Draw walls\n        for i in range(self.maze_size):\n            for j in range(self.maze_size):\n                cell_y, cell_x = i * 2 + 1, j * 2 + 1\n                if self.maze[0, i, j]:  # Top wall\n                    maze_render[cell_y - 1, cell_x] = '─'\n                if self.maze[1, i, j]:  # Right wall\n                    maze_render[cell_y, cell_x + 1] = '│'\n                if self.maze[2, i, j]:  # Bottom wall\n                    maze_render[cell_y + 1, cell_x] = '─'\n                if self.maze[3, i, j]:  # Left wall\n                    maze_render[cell_y, cell_x - 1] = '│'\n\n        # Mark start, goal, and current position\n        start_y, start_x = 1, 1\n        goal_y, goal_x = self.maze_size * 2 - 1, self.maze_size * 2 - 1\n        agent_y, agent_x = self.state[0] * 2 + 1, self.state[1] * 2 + 1\n\n        maze_render[start_y, start_x] = 'S'\n        maze_render[goal_y, goal_x] = 'G'\n        maze_render[agent_y, agent_x] = 'A'\n\n        # Print the maze\n        for row in maze_render:\n            print(''.join(row))\n        print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T02:31:58.764028Z","iopub.execute_input":"2024-08-07T02:31:58.764470Z","iopub.status.idle":"2024-08-07T02:31:58.810105Z","shell.execute_reply.started":"2024-08-07T02:31:58.764432Z","shell.execute_reply":"2024-08-07T02:31:58.809172Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch as th\nimport torch.nn as nn\nfrom stable_baselines3.common.torch_layers import BaseFeaturesExtractor\nimport gymnasium as gym\n\nclass CustomCNN(BaseFeaturesExtractor):\n    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 100):\n        super(CustomCNN, self).__init__(observation_space, features_dim)\n        \n        # The input will now have the channel dimension first\n        n_input_channels = observation_space.shape[0]\n        \n        self.cnn = nn.Sequential(\n            nn.Conv2d(n_input_channels, 32, kernel_size=(3, 3), stride=(1, 1)),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1)),\n            nn.ReLU(),\n            nn.Flatten()\n        )\n\n        # Compute shape by doing one forward pass\n        with th.no_grad():\n            n_flatten = self.cnn(\n                th.as_tensor(observation_space.sample()[None]).float()\n            ).shape[1]\n        \n        self.linear = nn.Linear(n_flatten, features_dim)\n        \n    def forward(self, observations: th.Tensor) -> th.Tensor:\n        return self.linear(self.cnn(observations))\n\n# Create the DQN model with CustomCNN\npolicy_kwargs = dict(\n    features_extractor_class=CustomCNN,\n    net_arch=[64,64]\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T02:31:58.811423Z","iopub.execute_input":"2024-08-07T02:31:58.812311Z","iopub.status.idle":"2024-08-07T02:32:14.124252Z","shell.execute_reply.started":"2024-08-07T02:31:58.812267Z","shell.execute_reply":"2024-08-07T02:32:14.123475Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2024-08-07 02:32:04.348949: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-07 02:32:04.349056: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-07 02:32:04.482134: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create the environment\n# env = CustomMazeEnvMlp(maze_data=MAZE_DATA)\n# env = CustomMazeEnvCNNIMG(maze_data=MAZE_DATA)\n# env = CustomMazeEnv(maze_data=MAZE_DATA)\n# env = CustomMazeEnvMlpImproved(maze_data=MAZE_DATA)\nenv = CustomMazeEnvCNNIMGML(maze_data_list=maze_data_list, max_steps_per_episode=1, maze_size=10, random_start=True)\n\n# Verify the environment\nprint(\"Observation space:\", env.observation_space)\nprint(\"Action space:\", env.action_space)\n\n# Test the environment with random actions\nobs, _ = env.reset(42)\nfor _ in range(10):\n    # action = env.action_space.sample()  # take a random action\n    action = 1\n    obs, reward, terminated, truncated, info = env.step(action)\n    print(\"State:\", env.state, \"Action:\", action, \"Reward:\", reward, \"Terminated:\", terminated, \"Truncated:\", truncated)\n    env.render()\n    # env.render_binary()\n    print(obs)\n    if terminated or truncated:\n        obs, _ = env.reset()","metadata":{"execution":{"iopub.status.busy":"2024-08-07T02:32:14.125443Z","iopub.execute_input":"2024-08-07T02:32:14.126170Z","iopub.status.idle":"2024-08-07T02:32:14.253958Z","shell.execute_reply.started":"2024-08-07T02:32:14.126128Z","shell.execute_reply":"2024-08-07T02:32:14.252794Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Observation space: Box(0, 255, (84, 84, 3), uint8)\nAction space: Discrete(4)\nState: (0, 8) Action: 1 Reward: -1 Terminated: True Truncated: True\n[[[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n ...\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [255 255 255]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]]\nState: (5, 6) Action: 1 Reward: -10 Terminated: True Truncated: True\n[[[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n ...\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [255 255 255]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]]\nState: (6, 2) Action: 1 Reward: -1 Terminated: True Truncated: True\n[[[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n ...\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [255 255 255]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]]\nState: (9, 5) Action: 1 Reward: -10 Terminated: True Truncated: True\n[[[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n ...\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [255 255 255]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]]\nState: (5, 9) Action: 1 Reward: -10 Terminated: True Truncated: True\n[[[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n ...\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [255 255 255]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]]\nState: (0, 8) Action: 1 Reward: -1 Terminated: True Truncated: True\n[[[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n ...\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [255 255 255]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]]\nState: (1, 4) Action: 1 Reward: -1 Terminated: True Truncated: True\n[[[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n ...\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [255 255 255]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]]\nState: (0, 4) Action: 1 Reward: -1 Terminated: True Truncated: True\n[[[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n ...\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [255 255 255]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]]\nState: (7, 8) Action: 1 Reward: -1 Terminated: True Truncated: True\n[[[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n ...\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [255 255 255]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]]\nState: (3, 9) Action: 1 Reward: -10 Terminated: True Truncated: True\n[[[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n ...\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [255 255 255]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [  0   0   0]\n  ...\n  [  0   0   0]\n  [  0   0   0]\n  [255 255 255]]\n\n [[255 255 255]\n  [255 255 255]\n  [255 255 255]\n  ...\n  [255 255 255]\n  [255 255 255]\n  [255 255 255]]]\n","output_type":"stream"}]},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"3e0201b52f7e9c9458608859c4e12c2d7b64a9b8\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T02:32:14.255090Z","iopub.execute_input":"2024-08-07T02:32:14.255451Z","iopub.status.idle":"2024-08-07T02:32:16.393370Z","shell.execute_reply.started":"2024-08-07T02:32:14.255417Z","shell.execute_reply":"2024-08-07T02:32:16.392585Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Error: no \"view\" mailcap rules found for type \"image/png\"\nError: no \"view\" mailcap rules found for type \"image/png\"\nError: no \"view\" mailcap rules found for type \"image/png\"\nError: no \"view\" mailcap rules found for type \"image/png\"\nError: no \"view\" mailcap rules found for type \"image/png\"\nError: no \"view\" mailcap rules found for type \"image/png\"\n/usr/bin/xdg-open: 869: www-browser: not found\n/usr/bin/xdg-open: 869: www-browser: not found\n/usr/bin/xdg-open: 869: www-browser: not found\n/usr/bin/xdg-open: 869: www-browser: not found\n/usr/bin/xdg-open: 869: links2: not found\n/usr/bin/xdg-open: 869: www-browser: not found\n/usr/bin/xdg-open: 869: www-browser: not found\n/usr/bin/xdg-open: 869: links2: not found\n/usr/bin/xdg-open: 869: links2: not found\n/usr/bin/xdg-open: 869: links2: not found\n/usr/bin/xdg-open: 869: links2: not found\n/usr/bin/xdg-open: 869: elinks: not found\n/usr/bin/xdg-open: 869: links2: not found\n/usr/bin/xdg-open: 869: elinks: not found\n/usr/bin/xdg-open: 869: elinks: not found\n/usr/bin/xdg-open: 869: elinks: not found\n/usr/bin/xdg-open: 869: elinks: not found\nError: no \"view\" mailcap rules found for type \"image/png\"\nError: no \"view\" mailcap rules found for type \"image/png\"\n/usr/bin/xdg-open: 869: links: not found\n/usr/bin/xdg-open: 869: links: not found\n/usr/bin/xdg-open: 869: links: not found\n/usr/bin/xdg-open: 869: links: not found\n/usr/bin/xdg-open: 869: www-browser: not found\n/usr/bin/xdg-open: 869: lynx: not found\n/usr/bin/xdg-open: 869: lynx: not found\n/usr/bin/xdg-open: 869: elinks: not found\n/usr/bin/xdg-open: 869: lynx: not found\n/usr/bin/xdg-open: 869: www-browser: not found\n/usr/bin/xdg-open: 869: links: not found\n/usr/bin/xdg-open: 869: links2: not found\n/usr/bin/xdg-open: 869: w3m: not found\nxdg-open: no method available for opening '/tmp/tmpbhjfw1l7.PNG'\n/usr/bin/xdg-open: 869: links: not found\n/usr/bin/xdg-open: 869: w3m: not found\nxdg-open: no method available for opening '/tmp/tmpxo801t5p.PNG'\n/usr/bin/xdg-open: 869: lynx: not found\n/usr/bin/xdg-open: 869: w3m: not found\nxdg-open: no method available for opening '/tmp/tmpuqyu9a6z.PNG'\n/usr/bin/xdg-open: 869: links2: not found\n/usr/bin/xdg-open: 869: elinks: not found\n/usr/bin/xdg-open: 869: lynx: not found\n/usr/bin/xdg-open: 869: elinks: not found\n/usr/bin/xdg-open: 869: lynx: not found\n/usr/bin/xdg-open: 869: links: not found\n/usr/bin/xdg-open: 869: w3m: not found\nxdg-open: no method available for opening '/tmp/tmpjx3430gy.PNG'\n/usr/bin/xdg-open: 869: w3m: not found\nxdg-open: no method available for opening '/tmp/tmpkt__a_vx.PNG'\nError: no \"view\" mailcap rules found for type \"image/png\"\n/usr/bin/xdg-open: 869: links: not found\n/usr/bin/xdg-open: 869: lynx: not found\n/usr/bin/xdg-open: 869: w3m: not found\nxdg-open: no method available for opening '/tmp/tmp7z2ca359.PNG'\n/usr/bin/xdg-open: 869: lynx: not found\n/usr/bin/xdg-open: 869: w3m: not found\nxdg-open: no method available for opening '/tmp/tmpf3d1x0gf.PNG'\n/usr/bin/xdg-open: 869: w3m: not found\nxdg-open: no method available for opening '/tmp/tmpmmfmihud.PNG'\nError: no \"view\" mailcap rules found for type \"image/png\"\n/usr/bin/xdg-open: 869: www-browser: not found\n/usr/bin/xdg-open: 869: links2: not found\n/usr/bin/xdg-open: 869: www-browser: not found\n/usr/bin/xdg-open: 869: /usr/bin/xdg-open: 869: elinks: not found\nlinks2: not found\n/usr/bin/xdg-open: 869: elinks: not found\n/usr/bin/xdg-open: 869: links: not found\n/usr/bin/xdg-open: 869: links: not found\n/usr/bin/xdg-open: 869: lynx: not found\n/usr/bin/xdg-open: 869: lynx: not found\n/usr/bin/xdg-open: 869: w3m: not found\nxdg-open: no method available for opening '/tmp/tmpf7e6o_vk.PNG'\n/usr/bin/xdg-open: 869: w3m: not found\nxdg-open: no method available for opening '/tmp/tmpyfuep9xx.PNG'\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import wandb\nimport torch\nfrom stable_baselines3.common.callbacks import BaseCallback\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nclass WandbCallbackMod(BaseCallback):\n    def __init__(self, verbose=0):\n        super().__init__(verbose)\n        self.cumulative_reward = 0\n        self.episode_reward = 0\n        self.success_count = 0\n        self.episode_count = 0\n\n    def _on_step(self):\n        # Log all available metrics from the logger\n        for key, value in self.model.logger.name_to_value.items():\n            wandb.log({key: value}, step=self.num_timesteps)\n        \n        reward = self.model.env.get_attr('reward')[0]\n        \n        self.cumulative_reward += reward\n        self.episode_reward += reward\n        \n        if self.model.env.get_attr('done')[0]:\n            # Increment the episode count\n            self.episode_count += 1\n            \n            # If the episode was successful, increment the success count\n            if self.model.env.get_attr('is_success')[0]:\n                self.success_count += 1\n            \n            wandb.log({\n                'train/cumulative_reward': self.cumulative_reward,\n                'train/episode_reward': self.episode_reward,\n                'train/success_rate': self.success_count / self.episode_count\n            }, step=self.num_timesteps)\n            \n            # Reset the episode reward\n            self.episode_reward = 0\n\n        return True\n    \n    def _on_training_end(self):\n        wandb.finish()\n        \n        return None","metadata":{"execution":{"iopub.status.busy":"2024-08-07T02:32:16.394399Z","iopub.execute_input":"2024-08-07T02:32:16.394962Z","iopub.status.idle":"2024-08-07T02:32:16.428365Z","shell.execute_reply.started":"2024-08-07T02:32:16.394936Z","shell.execute_reply":"2024-08-07T02:32:16.427432Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from stable_baselines3 import DQN\n\nenv_mlp_ml = CustomMazeEnvMlpML(maze_data_list=maze_data_list_alot, max_steps_per_episode=400, maze_size=10, random_start=True)\n\nmodel_mlp_ml = DQN(\n    \"MlpPolicy\",\n    env_mlp_ml,\n    learning_rate=1e-4,\n    buffer_size=1000,\n    learning_starts=100,\n    batch_size=32,\n    gamma=0.85,\n    target_update_interval=5,\n    exploration_fraction = 0.8,\n    exploration_initial_eps=1.0,\n    exploration_final_eps=0.5,\n    device=device,\n    verbose=1,\n    seed=42,\n)\n\ncallback = WandbCallbackMod()","metadata":{"execution":{"iopub.status.busy":"2024-08-07T02:32:16.429687Z","iopub.execute_input":"2024-08-07T02:32:16.430230Z","iopub.status.idle":"2024-08-07T02:32:18.065350Z","shell.execute_reply.started":"2024-08-07T02:32:16.430196Z","shell.execute_reply":"2024-08-07T02:32:18.064568Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Using cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"}]},{"cell_type":"code","source":"wandb.init(project=\"maze-dqn\", name=\"stable-mlp-maze-10-5-testcount\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T02:32:18.074026Z","iopub.execute_input":"2024-08-07T02:32:18.074260Z","iopub.status.idle":"2024-08-07T02:32:35.265818Z","shell.execute_reply.started":"2024-08-07T02:32:18.074240Z","shell.execute_reply":"2024-08-07T02:32:35.264843Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjeremyrio\u001b[0m (\u001b[33mjeremyrp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240807_023218-za8psv4p</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jeremyrp/maze-dqn/runs/za8psv4p' target=\"_blank\">stable-encode-maze-10-1-testcount</a></strong> to <a href='https://wandb.ai/jeremyrp/maze-dqn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jeremyrp/maze-dqn' target=\"_blank\">https://wandb.ai/jeremyrp/maze-dqn</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jeremyrp/maze-dqn/runs/za8psv4p' target=\"_blank\">https://wandb.ai/jeremyrp/maze-dqn/runs/za8psv4p</a>"},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/jeremyrp/maze-dqn/runs/za8psv4p?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7af7f720ebf0>"},"metadata":{}}]},{"cell_type":"code","source":"model_mlp_ml.learn(total_timesteps=2000000, callback=[callback], log_interval=1000)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T02:32:35.266888Z","iopub.execute_input":"2024-08-07T02:32:35.267180Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/gymnasium/core.py:297: UserWarning: \u001b[33mWARN: env.reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.reward` for environment variables or `env.get_attr('reward')` that will search the reminding wrappers.\u001b[0m\n  logger.warn(\n/opt/conda/lib/python3.10/site-packages/gymnasium/core.py:297: UserWarning: \u001b[33mWARN: env.done to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.done` for environment variables or `env.get_attr('done')` that will search the reminding wrappers.\u001b[0m\n  logger.warn(\n/opt/conda/lib/python3.10/site-packages/gymnasium/core.py:297: UserWarning: \u001b[33mWARN: env.is_success to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_success` for environment variables or `env.get_attr('is_success')` that will search the reminding wrappers.\u001b[0m\n  logger.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"model_mlp_ml.save(\"stable-mlp-maze-10-5-testcount\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}